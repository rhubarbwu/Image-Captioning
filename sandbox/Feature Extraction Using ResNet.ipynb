{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_one = r\"C:\\Users\\jiyun\\Desktop\\Jiyu\\2020-2021\\Winter\\CSC413 - Neural Networks and Deep Learnin\\Final Project\\Image-Captioning-Reproduction\\data\\val2014\\val2014\\COCO_val2014_000000000285.jpg\"\n",
    "pic_two = r\"C:\\Users\\jiyun\\Desktop\\Jiyu\\2020-2021\\Winter\\CSC413 - Neural Networks and Deep Learnin\\Final Project\\Image-Captioning-Reproduction\\data\\val2014\\val2014\\COCO_val2014_000000000502.jpg\"\n",
    "# pic_one = str(path_one)\n",
    "# pic_two = str(path_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained model\n",
    "model = models.resnet18(pretrained=True)\n",
    "# Use the model object to select the desired layer\n",
    "layer = model._modules.get('avgpool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiyun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torchvision\\transforms\\transforms.py:279: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
     ]
    }
   ],
   "source": [
    "scaler = transforms.Scale((224, 224))\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(image_name):\n",
    "    # 1. Load the image with Pillow library\n",
    "    img = Image.open(image_name)\n",
    "    # 2. Create a PyTorch Variable with the transformed image\n",
    "    t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0))\n",
    "    # 3. Create a vector of zeros that will hold our feature vector\n",
    "    #    The 'avgpool' layer has an output size of 512\n",
    "    my_embedding = torch.zeros(512)\n",
    "#     import pdb; pdb.set_trace()\n",
    "    # 4. Define a function that will copy the output of a layer\n",
    "    def copy_data(m, i, o):\n",
    "        my_embedding.copy_(o.data.reshape(o.data.size(1)))\n",
    "    # 5. Attach that function to our selected layer\n",
    "    h = layer.register_forward_hook(copy_data)\n",
    "    # 6. Run the model on our transformed image\n",
    "    model(t_img)\n",
    "    # 7. Detach our copy function from the layer\n",
    "    h.remove()\n",
    "    # 8. Return the feature vector\n",
    "    return my_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_one_vector = get_vector(pic_one)\n",
    "pic_two_vector = get_vector(pic_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7028])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using PyTorch Cosine Similarity\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "cos_sim = cos(pic_one_vector.unsqueeze(0),\n",
    "              pic_two_vector.unsqueeze(0))\n",
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7826e+00, 2.5210e-01, 1.2422e+00, 4.7411e-01, 1.6703e+00, 1.7719e-01,\n",
       "        1.2750e+00, 2.0410e+00, 6.7764e-01, 8.9163e-01, 4.4451e-01, 9.1998e-01,\n",
       "        3.4095e+00, 7.9513e-02, 1.5283e+00, 2.8774e-01, 7.4838e-01, 1.9869e+00,\n",
       "        7.4925e-01, 6.1960e-02, 2.0624e-01, 1.8651e+00, 1.8422e+00, 1.2656e+00,\n",
       "        4.2586e-01, 0.0000e+00, 8.6108e-01, 1.3742e+00, 4.9021e-01, 2.4977e+00,\n",
       "        1.0179e-01, 2.6996e-03, 2.0250e+00, 3.1927e-01, 5.2740e-01, 8.6557e-01,\n",
       "        2.2881e-01, 1.7459e+00, 3.6572e-01, 2.0296e+00, 3.9448e-02, 1.6928e+00,\n",
       "        1.4204e+00, 8.0132e-01, 2.6842e-01, 1.1884e+00, 3.3753e+00, 2.2603e-01,\n",
       "        2.1726e-01, 7.1075e-01, 1.5467e+00, 1.1236e+00, 3.6591e-01, 9.7498e-01,\n",
       "        5.4708e-01, 3.7703e-01, 3.4217e+00, 9.9709e-02, 3.9140e-01, 2.0770e+00,\n",
       "        1.4149e+00, 1.2824e+00, 1.9456e+00, 2.5578e+00, 4.9412e-02, 1.8026e+00,\n",
       "        2.8715e-01, 1.1501e-01, 5.6986e-01, 2.5310e-01, 1.7087e+00, 3.6262e-02,\n",
       "        3.1162e-01, 2.0679e+00, 1.0460e+00, 8.8452e-01, 1.9473e+00, 2.0072e-01,\n",
       "        8.2753e-01, 5.4907e-01, 1.5780e+00, 1.0648e+00, 3.7750e-01, 1.3587e+00,\n",
       "        4.3832e-01, 2.8293e+00, 1.5221e-02, 9.9141e-01, 1.4172e+00, 1.3495e-01,\n",
       "        3.2404e-01, 9.8157e-01, 1.5507e+00, 1.7910e+00, 8.1476e-01, 1.2420e+00,\n",
       "        3.2520e-01, 1.7676e+00, 6.4174e-01, 9.5873e-01, 4.5287e+00, 1.4403e+00,\n",
       "        4.0937e-01, 1.2178e+00, 7.5835e-01, 3.4434e-02, 1.3145e+00, 5.6501e-01,\n",
       "        0.0000e+00, 2.5606e-01, 1.6772e-01, 9.4739e-01, 2.1387e+00, 1.2954e-02,\n",
       "        6.8889e-02, 3.3151e-01, 3.6190e-01, 1.9110e+00, 1.5247e+00, 1.4428e+00,\n",
       "        3.2009e+00, 2.8503e-01, 4.4539e-01, 7.4911e-02, 9.1909e-01, 1.4576e+00,\n",
       "        1.1530e+00, 2.6244e+00, 2.2475e-01, 2.1843e+00, 1.1988e+00, 3.5097e-01,\n",
       "        2.3984e-01, 1.7561e+00, 1.0321e+00, 2.1197e+00, 3.6442e+00, 2.4898e-01,\n",
       "        2.7096e-01, 3.8000e-01, 6.2217e-02, 9.7470e-01, 6.1210e-01, 4.6798e+00,\n",
       "        2.4174e+00, 1.0951e+00, 2.9614e+00, 4.4308e+00, 9.8667e-01, 9.7250e-01,\n",
       "        5.0800e-01, 1.6021e-01, 2.8423e+00, 1.0521e+00, 6.1664e-01, 1.6632e-01,\n",
       "        8.7127e-01, 1.6628e+00, 6.6592e-01, 2.7797e+00, 2.1698e-01, 1.0130e+00,\n",
       "        3.6148e-01, 6.2837e-01, 1.5062e+00, 1.5057e+00, 1.1435e+00, 5.2996e-01,\n",
       "        2.9648e-01, 1.1187e-01, 1.4202e+00, 1.5048e+00, 1.8963e-01, 7.3416e-01,\n",
       "        4.1413e-01, 9.7118e-01, 8.7551e-01, 5.7972e-03, 1.1041e+00, 1.2346e+00,\n",
       "        1.3124e+00, 1.3390e+00, 6.3562e-01, 6.6251e-01, 3.9974e-02, 2.6201e+00,\n",
       "        3.6571e-01, 4.8167e+00, 6.1565e-02, 3.9373e-01, 1.0738e+00, 7.3158e-01,\n",
       "        1.0114e-01, 3.7266e-01, 1.4544e+00, 8.2706e-01, 4.0047e-02, 2.6936e-01,\n",
       "        4.7503e-01, 6.8145e-01, 1.5313e+00, 2.6281e+00, 2.5580e+00, 9.6204e-02,\n",
       "        1.0165e+00, 1.2533e+00, 8.0796e-01, 9.6105e-01, 2.3312e+00, 8.2634e-01,\n",
       "        1.1514e+00, 1.7937e+00, 7.8951e-01, 4.0897e+00, 1.3344e+00, 1.2655e+00,\n",
       "        2.3035e+00, 5.0971e-02, 2.0175e-01, 1.3548e-01, 2.0894e-01, 7.3526e-01,\n",
       "        1.6879e-01, 7.3216e-01, 4.1746e-01, 1.4972e-02, 4.7362e-01, 5.4570e-01,\n",
       "        8.8079e-01, 4.8148e-01, 1.2154e+00, 4.1028e-01, 1.1175e+00, 3.4149e-01,\n",
       "        5.7972e-01, 5.0037e-01, 1.1786e+00, 9.0694e-01, 7.7508e-01, 2.7298e-01,\n",
       "        3.6990e-01, 6.9038e-01, 3.7513e-01, 1.6159e+00, 3.6489e-01, 1.3302e-01,\n",
       "        1.6470e-02, 7.0158e-01, 3.3736e-02, 1.2998e+00, 3.9294e+00, 3.4709e-02,\n",
       "        1.6961e+00, 1.1257e-01, 2.5070e-02, 2.4273e+00, 6.7312e-04, 1.4885e+00,\n",
       "        1.4810e+00, 2.7059e+00, 1.3157e+00, 4.3093e+00, 1.0090e-01, 9.8608e-01,\n",
       "        2.5246e+00, 8.6849e-02, 9.5919e-02, 2.0123e-01, 7.0358e-01, 1.8150e+00,\n",
       "        1.6617e+00, 5.2137e+00, 3.1791e-01, 7.4573e-01, 6.6431e-01, 5.7089e-01,\n",
       "        2.8541e+00, 1.3218e+00, 2.2606e+00, 2.3603e-01, 2.8567e-01, 5.9607e-01,\n",
       "        1.3912e+00, 0.0000e+00, 1.5434e+00, 1.9523e+00, 7.9978e-01, 0.0000e+00,\n",
       "        2.4342e+00, 1.0493e+00, 4.9823e-02, 4.6423e-01, 1.1779e+00, 1.2722e-02,\n",
       "        1.5145e+00, 3.3952e-02, 1.3085e+00, 2.2065e+00, 3.7150e+00, 4.0942e-01,\n",
       "        8.2549e-02, 1.4618e+00, 3.1122e-01, 5.1227e-01, 5.5597e-01, 5.3860e-02,\n",
       "        4.2685e+00, 1.0884e-01, 6.3470e-01, 2.6410e-01, 2.6011e+00, 3.1069e-01,\n",
       "        1.8698e+00, 8.2091e-01, 2.3039e+00, 1.1242e+00, 1.6504e+00, 3.1237e-01,\n",
       "        9.0257e-01, 4.0472e-01, 1.4818e+00, 7.3141e-01, 9.6080e-01, 1.2379e+00,\n",
       "        5.8169e-02, 5.5424e-02, 1.4919e-01, 7.5998e-01, 1.7537e+00, 5.4294e-01,\n",
       "        3.5817e-01, 9.2163e-01, 2.6578e-01, 1.9374e+00, 5.4510e-01, 9.7770e-01,\n",
       "        2.0132e-01, 9.8586e-01, 1.0172e+00, 2.0634e+00, 7.0203e-01, 5.9468e-01,\n",
       "        2.2474e+00, 7.2713e-01, 2.6638e-01, 9.9740e-01, 4.7576e-01, 1.1247e+00,\n",
       "        2.5740e+00, 3.5069e-01, 7.5668e-01, 1.3753e+00, 1.7669e+00, 1.2630e+00,\n",
       "        4.0797e-01, 1.7704e+00, 1.9265e+00, 9.0522e-01, 2.2057e-01, 3.7282e-01,\n",
       "        1.4640e+00, 2.5701e-01, 1.0455e-01, 9.4401e-01, 4.5053e-01, 4.8507e-01,\n",
       "        6.2868e-01, 3.6874e-01, 1.5688e+00, 3.5130e-01, 1.7256e+00, 1.0839e-01,\n",
       "        8.2575e-01, 1.1309e+00, 2.0067e+00, 1.4174e-01, 4.4088e-01, 1.3230e-01,\n",
       "        3.2986e+00, 1.9205e+00, 1.6680e-01, 1.2008e+00, 1.1629e+00, 5.9069e-02,\n",
       "        3.9145e-01, 4.5118e-01, 2.3450e-01, 1.2018e+00, 1.9853e-01, 2.7856e-02,\n",
       "        1.2249e+00, 2.7383e+00, 3.8100e-01, 1.8070e+00, 9.1314e-01, 9.4893e-02,\n",
       "        3.5374e-01, 7.7965e-01, 3.8888e-02, 1.5389e+00, 1.4497e+00, 0.0000e+00,\n",
       "        1.9574e-01, 6.7317e-01, 9.6634e-02, 4.6296e-01, 1.1830e+00, 3.9435e-01,\n",
       "        1.9067e+00, 3.8157e-01, 3.6315e-01, 3.7705e-03, 6.6398e-02, 0.0000e+00,\n",
       "        2.0384e+00, 8.0844e-01, 6.0648e-01, 1.8589e-02, 3.8472e+00, 7.9916e-01,\n",
       "        5.6302e-03, 1.9939e+00, 1.2643e+00, 8.0425e-01, 2.2355e+00, 1.4419e-01,\n",
       "        2.2378e-01, 5.3967e-02, 3.6232e+00, 4.3001e-01, 9.0389e-01, 1.1413e+00,\n",
       "        8.5388e-01, 5.8072e+00, 1.4095e-01, 1.1377e+00, 6.9100e-01, 1.3929e+00,\n",
       "        1.6255e+00, 8.0069e-01, 1.4431e+00, 5.8517e-01, 6.8630e-02, 7.1211e-01,\n",
       "        2.5189e+00, 1.7676e-01, 2.1779e-01, 3.9544e-01, 7.6985e-01, 2.5126e-01,\n",
       "        2.4592e+00, 1.3234e+00, 2.5987e+00, 9.3065e-01, 9.0901e-01, 2.7177e-01,\n",
       "        1.3828e-01, 7.1707e-01, 2.6674e-01, 1.1996e+00, 1.9256e-01, 3.0905e-01,\n",
       "        1.1910e+00, 8.6937e-01, 5.9573e-01, 2.0828e+00, 4.0534e-01, 2.9041e+00,\n",
       "        2.2625e+00, 4.1852e-01, 3.8321e-01, 5.5400e-01, 4.9985e-02, 2.0574e+00,\n",
       "        3.2186e-01, 1.4953e+00, 7.1735e-01, 7.1517e-01, 4.3718e-01, 1.3001e-01,\n",
       "        1.6147e-01, 5.1029e-01, 3.1867e-01, 1.4107e+00, 6.4674e-01, 4.7426e-01,\n",
       "        1.3618e+00, 1.0109e-01, 7.9314e-01, 1.8180e+00, 2.6232e-01, 1.1931e+00,\n",
       "        2.8202e+00, 4.3503e+00, 2.9801e+00, 1.4804e-01, 1.8905e+00, 1.6401e+00,\n",
       "        1.1865e+00, 6.3205e-02, 1.4764e+00, 5.1477e-01, 3.2155e+00, 1.8908e-01,\n",
       "        6.5654e-01, 4.8922e-01, 1.8283e+00, 6.9645e-01, 2.4727e-01, 8.0508e-01,\n",
       "        3.0749e+00, 3.0799e-02])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic_one_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CocoCaptions\n",
    "from pycocotools.coco import COCO\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.68s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_dataset = CocoCaptions(\n",
    "    root=\"../data/val2014/val2014\", \n",
    "    annFile=\"../annotations/annotations_trainval2014/annotations/captions_val2014.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=640x426 at 0x7F4553744DC0>,\n",
       " ['An airplane with wheels wheels barely off ground tilted slightly upward from the pavement to the blue sky.',\n",
       "  'A small plane is taking off from a sandy beach',\n",
       "  'A white airplane is driving down the runway.',\n",
       "  'Small plane inches above flat surface near water.',\n",
       "  'A small plane on the sand near a beach.'])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(coco_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_format_transform_repr',\n",
       " '_repr_indent',\n",
       " 'coco',\n",
       " 'extra_repr',\n",
       " 'ids',\n",
       " 'root',\n",
       " 'target_transform',\n",
       " 'transform',\n",
       " 'transforms']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(coco_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CocoCaptions' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-3cf445c33e7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcoco_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'CocoCaptions' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "coco_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for ids, x in tqdm(zip(coco_dataset.ids, coco_dataset)):\n",
    "    count +=1\n",
    "    print(ids)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40504"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coco_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image_id': 203564,\n",
       "  'id': 37,\n",
       "  'caption': 'A bicycle replica with a clock as the front wheel.'},\n",
       " {'image_id': 203564, 'id': 181, 'caption': 'The bike has a clock as a tire.'},\n",
       " {'image_id': 203564,\n",
       "  'id': 478,\n",
       "  'caption': 'A black metal bicycle with a clock inside the front wheel.'},\n",
       " {'image_id': 203564,\n",
       "  'id': 6637,\n",
       "  'caption': 'A bicycle figurine in which the front wheel is replaced with a clock\\n'},\n",
       " {'image_id': 203564,\n",
       "  'id': 6802,\n",
       "  'caption': 'A clock with the appearance of the wheel of a bicycle '}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_dataset.coco.imgToAnns[203564]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37, 181, 478, 6637, 6802]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_dataset.coco.getAnnIds(203564)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
